{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib 3.5.2\n",
      "numpy 1.23.0\n",
      "pandas 1.4.3\n",
      "sklearn 1.1.1\n",
      "tensorflow 2.9.1\n",
      "keras.api._v2.keras 2.9.0\n"
     ]
    }
   ],
   "source": [
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28) (5000,)\n",
      "(55000, 28, 28) (55000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
    "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# x_train: [None, 28, 28] -> [None, 784]\n",
    "x_train_scaled = scaler.fit_transform(x_train.reshape(-1, 1)).reshape(-1, 28, 28)\n",
    "x_valid_scaled = scaler.transform(x_valid.reshape(-1, 1)).reshape(-1, 28, 28)\n",
    "x_test_scaled = scaler.transform(x_test.reshape(-1, 1)).reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = keras.optimizers.SGD(0.001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,410\n",
      "Trainable params: 271,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x289d164a0d0>,\n",
       " <keras.layers.core.dense.Dense at 0x289c9604bb0>,\n",
       " <keras.layers.core.dense.Dense at 0x289d164a190>,\n",
       " <keras.layers.core.dense.Dense at 0x289eba6bca0>,\n",
       " <keras.layers.core.dense.Dense at 0x289eba6b970>,\n",
       " <keras.layers.core.dense.Dense at 0x289ebbf8f70>,\n",
       " <keras.layers.core.dense.Dense at 0x289ebc05fd0>,\n",
       " <keras.layers.core.dense.Dense at 0x289ebc0e490>,\n",
       " <keras.layers.core.dense.Dense at 0x289ebc0ec40>,\n",
       " <keras.layers.core.dense.Dense at 0x289ebc14a90>,\n",
       " <keras.layers.core.dense.Dense at 0x289ebc1d490>,\n",
       " <keras.layers.core.dense.Dense at 0x289ebc14790>,\n",
       " <keras.layers.core.dense.Dense at 0x289f1e56130>,\n",
       " <keras.layers.core.dense.Dense at 0x289ebc1de50>,\n",
       " <keras.layers.core.dense.Dense at 0x289f1e5d670>,\n",
       " <keras.layers.core.dense.Dense at 0x289f1e61d00>,\n",
       " <keras.layers.core.dense.Dense at 0x289f1e6a940>,\n",
       " <keras.layers.core.dense.Dense at 0x289f1e56b80>,\n",
       " <keras.layers.core.dense.Dense at 0x289f1e6afd0>,\n",
       " <keras.layers.core.dense.Dense at 0x289f1e79e80>,\n",
       " <keras.layers.core.dense.Dense at 0x289f1e79730>,\n",
       " <keras.layers.core.dense.Dense at 0x289c9604b20>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 21s 11ms/step - loss: 2.3014 - accuracy: 0.1227 - val_loss: 2.3001 - val_accuracy: 0.1374\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 2.2977 - accuracy: 0.1599 - val_loss: 2.2944 - val_accuracy: 0.1638\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 2.2889 - accuracy: 0.1797 - val_loss: 2.2808 - val_accuracy: 0.1768\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 2.2655 - accuracy: 0.1913 - val_loss: 2.2426 - val_accuracy: 0.1930\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 2.1868 - accuracy: 0.2112 - val_loss: 2.0867 - val_accuracy: 0.2034\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 1.7046 - accuracy: 0.3027 - val_loss: 1.2382 - val_accuracy: 0.4498\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 1.1325 - accuracy: 0.5169 - val_loss: 0.9782 - val_accuracy: 0.6110\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 0.9625 - accuracy: 0.5989 - val_loss: 0.9206 - val_accuracy: 0.6208\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 0.8870 - accuracy: 0.6364 - val_loss: 0.8193 - val_accuracy: 0.6776\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 18s 11ms/step - loss: 0.8341 - accuracy: 0.6638 - val_loss: 0.7669 - val_accuracy: 0.7060\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.7792 - accuracy: 0.6974 - val_loss: 0.7124 - val_accuracy: 0.7288\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.7481 - accuracy: 0.7153 - val_loss: 0.6634 - val_accuracy: 0.7538\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.7089 - accuracy: 0.7323 - val_loss: 0.7334 - val_accuracy: 0.7172\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 0.6665 - accuracy: 0.7498 - val_loss: 0.6602 - val_accuracy: 0.7556\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.6367 - accuracy: 0.7611 - val_loss: 0.6056 - val_accuracy: 0.7820\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.6110 - accuracy: 0.7721 - val_loss: 0.6404 - val_accuracy: 0.7074\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.5860 - accuracy: 0.7799 - val_loss: 0.5541 - val_accuracy: 0.7924\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 18s 11ms/step - loss: 0.5741 - accuracy: 0.7859 - val_loss: 0.5668 - val_accuracy: 0.7966\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.5448 - accuracy: 0.7968 - val_loss: 0.5958 - val_accuracy: 0.7890\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.5327 - accuracy: 0.8020 - val_loss: 0.5290 - val_accuracy: 0.8014\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.5187 - accuracy: 0.8103 - val_loss: 0.5443 - val_accuracy: 0.8008\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 0.5037 - accuracy: 0.8193 - val_loss: 0.5167 - val_accuracy: 0.8170\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.4928 - accuracy: 0.8243 - val_loss: 0.4973 - val_accuracy: 0.8256\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.4795 - accuracy: 0.8304 - val_loss: 0.4976 - val_accuracy: 0.8260\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.4746 - accuracy: 0.8347 - val_loss: 0.4859 - val_accuracy: 0.8320\n",
      "Epoch 26/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.4627 - accuracy: 0.8401 - val_loss: 0.5040 - val_accuracy: 0.8318\n",
      "Epoch 27/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.4503 - accuracy: 0.8447 - val_loss: 0.4891 - val_accuracy: 0.8294\n",
      "Epoch 28/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.4459 - accuracy: 0.8481 - val_loss: 0.5109 - val_accuracy: 0.8290\n",
      "Epoch 29/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.4348 - accuracy: 0.8514 - val_loss: 0.7009 - val_accuracy: 0.7412\n",
      "Epoch 30/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.4276 - accuracy: 0.8540 - val_loss: 0.4672 - val_accuracy: 0.8402\n",
      "Epoch 31/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.4143 - accuracy: 0.8584 - val_loss: 0.4681 - val_accuracy: 0.8414\n",
      "Epoch 32/100\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 0.4134 - accuracy: 0.8586 - val_loss: 0.6558 - val_accuracy: 0.7536\n",
      "Epoch 33/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.3986 - accuracy: 0.8643 - val_loss: 0.4680 - val_accuracy: 0.8398\n",
      "Epoch 34/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.3929 - accuracy: 0.8664 - val_loss: 0.4508 - val_accuracy: 0.8472\n",
      "Epoch 35/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.3854 - accuracy: 0.8694 - val_loss: 0.4397 - val_accuracy: 0.8530\n",
      "Epoch 36/100\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 0.4155 - accuracy: 0.8560 - val_loss: 0.5197 - val_accuracy: 0.8252\n",
      "Epoch 37/100\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 0.3820 - accuracy: 0.8714 - val_loss: 0.4352 - val_accuracy: 0.8554\n",
      "Epoch 38/100\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 0.3718 - accuracy: 0.8750 - val_loss: 0.4474 - val_accuracy: 0.8480\n",
      "Epoch 39/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.3620 - accuracy: 0.8773 - val_loss: 0.4426 - val_accuracy: 0.8510\n",
      "Epoch 40/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.3615 - accuracy: 0.8789 - val_loss: 0.4317 - val_accuracy: 0.8542\n",
      "Epoch 41/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.3517 - accuracy: 0.8817 - val_loss: 0.4449 - val_accuracy: 0.8526\n",
      "Epoch 42/100\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.3469 - accuracy: 0.8831 - val_loss: 0.4805 - val_accuracy: 0.8390\n",
      "Epoch 43/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.3500 - accuracy: 0.8836 - val_loss: 0.4360 - val_accuracy: 0.8544\n",
      "Epoch 44/100\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 0.3413 - accuracy: 0.8853 - val_loss: 0.4418 - val_accuracy: 0.8550\n",
      "Epoch 45/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.3340 - accuracy: 0.8879 - val_loss: 0.4489 - val_accuracy: 0.8548\n"
     ]
    }
   ],
   "source": [
    "logdir = './dnn-callbacks'\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "output_model_file = os.path.join(logdir, 'fashion_mnist_model.h5')\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(logdir),  # 画图使用\n",
    "    keras.callbacks.ModelCheckpoint(output_model_file, save_best_only = True),  # 保存模型的最佳参数\n",
    "    keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3),\n",
    "]\n",
    "history = model.fit(x_train_scaled, y_train, epochs=100,\n",
    "                    validation_data=(x_valid_scaled, y_valid),\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_vlim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test_scaled, y_test, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

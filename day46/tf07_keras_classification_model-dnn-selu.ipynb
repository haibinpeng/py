{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "sys.version_info(major=3, minor=8, micro=10, releaselevel='final', serial=0)\n",
      "matplotlib 3.5.2\n",
      "numpy 1.23.1\n",
      "pandas 1.4.3\n",
      "sklearn 1.1.1\n",
      "tensorflow 2.9.1\n",
      "keras.api._v2.keras 2.9.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28) (5000,)\n",
      "(55000, 28, 28) (55000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
    "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
    "\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# x_train: [None, 28, 28] -> [None, 784]\n",
    "x_train_scaled = scaler.fit_transform(\n",
    "    x_train.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28)\n",
    "x_valid_scaled = scaler.transform(\n",
    "    x_valid.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28)\n",
    "x_test_scaled = scaler.transform(\n",
    "    x_test.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\"))  # selu\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer = keras.optimizers.SGD(0.001),\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dense in module keras.layers.core.dense:\n",
      "\n",
      "class Dense(keras.engine.base_layer.Layer)\n",
      " |  Dense(*args, **kwargs)\n",
      " |  \n",
      " |  Just your regular densely-connected NN layer.\n",
      " |  \n",
      " |  `Dense` implements the operation:\n",
      " |  `output = activation(dot(input, kernel) + bias)`\n",
      " |  where `activation` is the element-wise activation function\n",
      " |  passed as the `activation` argument, `kernel` is a weights matrix\n",
      " |  created by the layer, and `bias` is a bias vector created by the layer\n",
      " |  (only applicable if `use_bias` is `True`). These are all attributes of\n",
      " |  `Dense`.\n",
      " |  \n",
      " |  Note: If the input to the layer has a rank greater than 2, then `Dense`\n",
      " |  computes the dot product between the `inputs` and the `kernel` along the\n",
      " |  last axis of the `inputs` and axis 0 of the `kernel` (using `tf.tensordot`).\n",
      " |  For example, if input has dimensions `(batch_size, d0, d1)`,\n",
      " |  then we create a `kernel` with shape `(d1, units)`, and the `kernel` operates\n",
      " |  along axis 2 of the `input`, on every sub-tensor of shape `(1, 1, d1)`\n",
      " |  (there are `batch_size * d0` such sub-tensors).\n",
      " |  The output in this case will have shape `(batch_size, d0, units)`.\n",
      " |  \n",
      " |  Besides, layer attributes cannot be modified after the layer has been called\n",
      " |  once (except the `trainable` attribute).\n",
      " |  When a popular kwarg `input_shape` is passed, then keras will create\n",
      " |  an input layer to insert before the current layer. This can be treated\n",
      " |  equivalent to explicitly defining an `InputLayer`.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  >>> # Create a `Sequential` model and add a Dense layer as the first layer.\n",
      " |  >>> model = tf.keras.models.Sequential()\n",
      " |  >>> model.add(tf.keras.Input(shape=(16,)))\n",
      " |  >>> model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
      " |  >>> # Now the model will take as input arrays of shape (None, 16)\n",
      " |  >>> # and output arrays of shape (None, 32).\n",
      " |  >>> # Note that after the first layer, you don't need to specify\n",
      " |  >>> # the size of the input anymore:\n",
      " |  >>> model.add(tf.keras.layers.Dense(32))\n",
      " |  >>> model.output_shape\n",
      " |  (None, 32)\n",
      " |  \n",
      " |  Args:\n",
      " |    units: Positive integer, dimensionality of the output space.\n",
      " |    activation: Activation function to use.\n",
      " |      If you don't specify anything, no activation is applied\n",
      " |      (ie. \"linear\" activation: `a(x) = x`).\n",
      " |    use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
      " |    bias_initializer: Initializer for the bias vector.\n",
      " |    kernel_regularizer: Regularizer function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_regularizer: Regularizer function applied to the bias vector.\n",
      " |    activity_regularizer: Regularizer function applied to\n",
      " |      the output of the layer (its \"activation\").\n",
      " |    kernel_constraint: Constraint function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_constraint: Constraint function applied to the bias vector.\n",
      " |  \n",
      " |  Input shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
      " |    The most common situation would be\n",
      " |    a 2D input with shape `(batch_size, input_dim)`.\n",
      " |  \n",
      " |  Output shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., units)`.\n",
      " |    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
      " |    the output would have shape `(batch_size, units)`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dense\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      keras.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call. It is invoked automatically before\n",
      " |      the first execution of `call()`.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses\n",
      " |      (at the discretion of the subclass implementer).\n",
      " |      \n",
      " |      Args:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      The `call()` method may not create state (except in its first invocation,\n",
      " |      wrapping the creation of variables or other resources in `tf.init_scope()`).\n",
      " |      It is recommended to create state in `__init__()`, or the `build()` method\n",
      " |      that is called automatically before `call()` executes the first time.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor, or dict/list/tuple of input tensors.\n",
      " |          The first positional `inputs` argument is subject to special rules:\n",
      " |          - `inputs` must be explicitly passed. A layer cannot have zero\n",
      " |            arguments, and `inputs` cannot be provided via the default value\n",
      " |            of a keyword argument.\n",
      " |          - NumPy array or Python scalar values in `inputs` get cast as tensors.\n",
      " |          - Keras mask metadata is only collected from `inputs`.\n",
      " |          - Layers are built (`build(input_shape)` method)\n",
      " |            using shape info from `inputs` only.\n",
      " |          - `input_spec` compatibility is only checked against `inputs`.\n",
      " |          - Mixed precision input casting is only applied to `inputs`.\n",
      " |            If a layer has tensor arguments in `*args` or `**kwargs`, their\n",
      " |            casting behavior in mixed precision should be handled manually.\n",
      " |          - The SavedModel input specification is generated using `inputs` only.\n",
      " |          - Integration with various ecosystem packages like TFMOT, TFLite,\n",
      " |            TF.js, etc is only supported for `inputs` and not for tensors in\n",
      " |            positional and keyword arguments.\n",
      " |        *args: Additional positional arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |        **kwargs: Additional keyword arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |          The following optional keyword arguments are reserved:\n",
      " |          - `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          - `mask`: Boolean input mask. If the layer's `call()` method takes a\n",
      " |            `mask` argument, its default value will be set to the mask generated\n",
      " |            for `inputs` by the previous layer (if `input` did come from a layer\n",
      " |            that generated a corresponding mask, i.e. if it came from a Keras\n",
      " |            layer with masking support).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      This method will cause the layer's state to be built, if that has not\n",
      " |      happened before. This requires that the layer will later be used with\n",
      " |      inputs that match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of dict\n",
      " |      every time it is called. The callers should make a copy of the returned dict\n",
      " |      if they want to modify it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |        - If the layer is not built, the method will call `build`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        **kwargs: Used for backwards compatibility only.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This is\n",
      " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result of\n",
      " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
      " |          using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  finalize_state(self)\n",
      " |      Finalizes the layers state after updating layer weights.\n",
      " |      \n",
      " |      This function can be subclassed in a layer and will be called after updating\n",
      " |      a layer weights. It can be overridden to finalize any additional layer state\n",
      " |      after a weight update.\n",
      " |      \n",
      " |      This function will be called after weights of a layer have been restored\n",
      " |      from a loaded model.\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer, as NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with this\n",
      " |      layer as a list of NumPy arrays, which can in turn be used to load state\n",
      " |      into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
      " |      and the bias vector. These can be used to set the weights of another\n",
      " |      `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of NumPy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
      " |      and the bias vector. These can be used to set the weights of another\n",
      " |      `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
      " |      computations and the output to be in the compute dtype as well. This is done\n",
      " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
      " |      these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision when\n",
      " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
      " |      will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Return Functional API nodes upstream of this layer.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of metrics added using the `add_metric()` API.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      >>> input = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2)\n",
      " |      >>> output = d(input)\n",
      " |      >>> d.add_metric(tf.reduce_max(output), name='max')\n",
      " |      >>> d.add_metric(tf.reduce_min(output), name='min')\n",
      " |      >>> [m.name for m in d.metrics]\n",
      " |      ['max', 'min']\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of `Metric` objects.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Return Functional API nodes downstream of this layer.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from keras.utils.version_utils.LayerVersionSelector:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.layers.Dense)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,410\n",
      "Trainable params: 271,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 23:17:00.047153: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 172480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6840 - accuracy: 0.7611 - val_loss: 0.5185 - val_accuracy: 0.8128\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4798 - accuracy: 0.8285 - val_loss: 0.4542 - val_accuracy: 0.8380\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4291 - accuracy: 0.8446 - val_loss: 0.4229 - val_accuracy: 0.8478\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3991 - accuracy: 0.8555 - val_loss: 0.4020 - val_accuracy: 0.8550\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3756 - accuracy: 0.8643 - val_loss: 0.4062 - val_accuracy: 0.8548\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3583 - accuracy: 0.8704 - val_loss: 0.3917 - val_accuracy: 0.8612\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3445 - accuracy: 0.8744 - val_loss: 0.3803 - val_accuracy: 0.8558\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3319 - accuracy: 0.8798 - val_loss: 0.3664 - val_accuracy: 0.8684\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3210 - accuracy: 0.8829 - val_loss: 0.3583 - val_accuracy: 0.8656\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3115 - accuracy: 0.8852 - val_loss: 0.3501 - val_accuracy: 0.8716\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3033 - accuracy: 0.8884 - val_loss: 0.3478 - val_accuracy: 0.8760\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2945 - accuracy: 0.8914 - val_loss: 0.3564 - val_accuracy: 0.8682\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2873 - accuracy: 0.8938 - val_loss: 0.3495 - val_accuracy: 0.8764\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2801 - accuracy: 0.8962 - val_loss: 0.3440 - val_accuracy: 0.8730\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2731 - accuracy: 0.8991 - val_loss: 0.3476 - val_accuracy: 0.8790\n"
     ]
    }
   ],
   "source": [
    "# Tensorboard, earlystopping, ModelCheckpoint\n",
    "logdir = './dnn-selu-callbacks'\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "output_model_file = os.path.join(logdir,\n",
    "                                 \"fashion_mnist_model.h5\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(logdir),\n",
    "    keras.callbacks.ModelCheckpoint(output_model_file,\n",
    "                                    save_best_only = True),\n",
    "    keras.callbacks.EarlyStopping(patience=5, min_delta=1e-2),\n",
    "]\n",
    "history = model.fit(x_train_scaled, y_train, epochs=100,\n",
    "                    validation_data=(x_valid_scaled, y_valid),\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.6840143203735352, 0.4797609746456146, 0.42913466691970825, 0.3991462290287018, 0.37563472986221313, 0.3583014905452728, 0.34453579783439636, 0.3319484293460846, 0.3210045099258423, 0.3114950656890869, 0.3033101260662079, 0.2945024371147156, 0.2872566878795624, 0.28007784485816956, 0.27309921383857727], 'accuracy': [0.761054515838623, 0.8284727334976196, 0.8446363806724548, 0.8554545640945435, 0.8642908930778503, 0.8704000115394592, 0.8744000196456909, 0.8797818422317505, 0.8828727006912231, 0.8852182030677795, 0.8884181976318359, 0.8913999795913696, 0.8938000202178955, 0.8961818218231201, 0.8990727066993713], 'val_loss': [0.5184644460678101, 0.45415663719177246, 0.4228820204734802, 0.40200501680374146, 0.4061632454395294, 0.39165908098220825, 0.38029393553733826, 0.3664225935935974, 0.35827916860580444, 0.3501482605934143, 0.3477729856967926, 0.3563908040523529, 0.3494749367237091, 0.34400057792663574, 0.34757694602012634], 'val_accuracy': [0.8127999901771545, 0.8379999995231628, 0.8478000164031982, 0.8550000190734863, 0.8547999858856201, 0.8611999750137329, 0.8557999730110168, 0.868399977684021, 0.8655999898910522, 0.8715999722480774, 0.8759999871253967, 0.8682000041007996, 0.8763999938964844, 0.8730000257492065, 0.8790000081062317]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.39170411229133606, 0.8626000285148621]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
